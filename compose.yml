services:

  telegram-bot:
    image: telegram-bot
    build:
      context: go-telegram/
      dockerfile: Dockerfile
    ports:
      - 3000:3000
    env_file: go-telegram/.env

  model-llama:
    image: llama3
    build:
      context: llama3
      dockerfile: Dockerfile
    ports:
      - 8007:8007
    volumes:
      - llm-models:/root/.cache/huggingface/hub/
    deploy:
      resources:
        reservations:
          devices: 
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  email-lambda:
    image: email-lambda
    build:
      context: email_lambda/
      dockerfile: Dockerfile
    ports:
      - "9000:8080"
    environment:
      - SENDER_EMAIL=${SENDER_EMAIL}
      - SENDER_PASSWORD=${SENDER_PASSWORD}
    entrypoint: ["/usr/local/bin/aws-lambda-rie"]
    command: ["./main"]


volumes:
  llm-models:
    driver: local